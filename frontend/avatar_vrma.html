<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ani VRMA - Professional Motion Capture Animation</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Segoe UI', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            overflow: hidden;
            color: white;
        }
        #canvas-container { width: 100vw; height: 100vh; position: relative; }
        #controls {
            position: absolute;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0, 0, 0, 0.7);
            padding: 20px 40px;
            border-radius: 50px;
            display: flex;
            gap: 15px;
            align-items: center;
            backdrop-filter: blur(10px);
        }
        button {
            padding: 12px 24px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            border: none;
            border-radius: 25px;
            color: white;
            font-size: 14px;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: 600;
        }
        button:hover { transform: translateY(-2px); }
        button.recording { background: linear-gradient(135deg, #f44336, #e91e63); }
        #status {
            position: absolute;
            top: 20px;
            left: 20px;
            background: rgba(0, 0, 0, 0.7);
            padding: 15px 25px;
            border-radius: 15px;
            font-size: 14px;
            backdrop-filter: blur(10px);
        }
        .status-dot {
            display: inline-block;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            margin-right: 8px;
        }
        .status-connected { background: #4CAF50; }
        .status-disconnected { background: #f44336; }
        .status-thinking { background: #FFC107; }
        #emotion-display {
            position: absolute;
            top: 20px;
            right: 20px;
            background: rgba(0, 0, 0, 0.7);
            padding: 15px 25px;
            border-radius: 15px;
            backdrop-filter: blur(10px);
        }
        #animation-info {
            position: absolute;
            top: 80px;
            right: 20px;
            background: rgba(0, 0, 0, 0.7);
            padding: 15px 25px;
            border-radius: 15px;
            backdrop-filter: blur(10px);
            font-size: 12px;
        }
        #loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            text-align: center;
            font-size: 24px;
            font-weight: 600;
        }
        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-top: 4px solid white;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            animation: spin 1s linear infinite;
            margin: 20px auto;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div id="canvas-container"></div>
    <div id="loading"><div class="spinner"></div>Loading VRMA System...</div>
    <div id="status" style="display: none;">
        <span class="status-dot status-disconnected"></span>
        <span id="status-text">Disconnected</span>
    </div>
    <div id="emotion-display" style="display: none;">
        <div style="opacity: 0.7; font-size: 12px; margin-bottom: 5px;">Emotion</div>
        <div id="emotion-text">Neutral</div>
    </div>
    <div id="animation-info" style="display: none;">
        <div style="opacity: 0.7; font-size: 10px;">Animation System</div>
        <div id="anim-name">VRMA Professional</div>
    </div>
    <div id="controls" style="display: none;">
        <button id="talk-btn">Hold to Talk</button>
        <span id="mic-status" style="font-size: 12px; opacity: 0.7;">Click and speak</span>
    </div>

    <script type="importmap">
    {
        "imports": {
            "three": "https://cdn.jsdelivr.net/npm/three@0.167.0/build/three.module.js",
            "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.167.0/examples/jsm/",
            "@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3.1.2/lib/three-vrm.module.js"
        }
    }
    </script>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';
        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';

        // State
        let scene, camera, renderer, controls;
        let currentVRM = null;
        let mixer = null;
        let currentAction = null;
        let ws = null;
        let recognition = null;
        let isListening = false;
        let currentAudio = null;
        const clock = new THREE.Clock();

        const EMOTION_MAP = {
            'joy': 'happy',
            'sad': 'sad',
            'anger': 'angry',
            'surprise': 'surprised',
            'neutral': 'neutral'
        };

        // Initialize scene
        function initScene() {
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x212121);

            camera = new THREE.PerspectiveCamera(30, window.innerWidth / window.innerHeight, 0.1, 100);
            camera.position.set(0, 1.4, 3);

            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            renderer.outputColorSpace = THREE.SRGBColorSpace;
            document.getElementById('canvas-container').appendChild(renderer.domElement);

            const directionalLight = new THREE.DirectionalLight(0xffffff, 1.5);
            directionalLight.position.set(1, 1, 1);
            scene.add(directionalLight);

            const ambientLight = new THREE.AmbientLight(0xffffff, 0.8);
            scene.add(ambientLight);

            const rimLight = new THREE.DirectionalLight(0x667eea, 0.5);
            rimLight.position.set(-1, 1, -1);
            scene.add(rimLight);

            controls = new OrbitControls(camera, renderer.domElement);
            controls.target.set(0, 1.2, 0);
            controls.enableDamping = true;
            controls.dampingFactor = 0.05;
            controls.update();

            window.addEventListener('resize', onWindowResize);
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        // Load VRM model
        async function loadVRM() {
            const loader = new GLTFLoader();
            loader.register((parser) => new VRMLoaderPlugin(parser));

            try {
                // Load VRM model
                const gltf = await loader.loadAsync('/character/darkhair.vrm');
                const vrm = gltf.userData.vrm;

                if (currentVRM) {
                    scene.remove(currentVRM.scene);
                    VRMUtils.deepDispose(currentVRM.scene);
                }

                currentVRM = vrm;
                scene.add(vrm.scene);
                vrm.scene.rotation.y = Math.PI;

                mixer = new THREE.AnimationMixer(vrm.scene);

                console.log('[OK] VRM model loaded');

                // Try to load VRMA animations first
                await loadVRMAAnimations();

                // Show UI
                document.getElementById('loading').style.display = 'none';
                document.getElementById('controls').style.display = 'flex';
                document.getElementById('status').style.display = 'block';
                document.getElementById('emotion-display').style.display = 'block';
                document.getElementById('animation-info').style.display = 'block';

            } catch (error) {
                console.error('[ERROR] Failed to load VRM:', error);
                document.getElementById('loading').innerHTML =
                    '<div style="color: #f44336;">Failed to load VRM</div>';
            }
        }

        // Load VRMA animation files
        async function loadVRMAAnimations() {
            // Try to load VRMA files (actual files from BOOTH download)
            const vrmaFiles = [
                '/animations/VRMA_02.vrma',  // Greeting pose
                '/animations/VRMA_06.vrma',  // Model pose
                '/animations/VRMA_01.vrma',  // Idle
                '/animations/VRMA_05.vrma',  // Alternative
            ];

            for (const vrmaPath of vrmaFiles) {
                try {
                    console.log(`[INFO] Trying to load VRMA: ${vrmaPath}`);
                    const response = await fetch(vrmaPath);

                    if (response.ok) {
                        const arrayBuffer = await response.arrayBuffer();
                        const blob = new Blob([arrayBuffer]);
                        const url = URL.createObjectURL(blob);

                        const loader = new GLTFLoader();
                        const gltf = await loader.loadAsync(url);

                        // VRMA files contain animation data in animations array
                        if (gltf.animations && gltf.animations.length > 0) {
                            const clip = gltf.animations[0];

                            console.log(`[DEBUG] Animation clip:`, clip.name, `Duration: ${clip.duration}s, Tracks: ${clip.tracks.length}`);

                            // Retarget animation to VRM humanoid bones
                            const retargetedClip = retargetAnimationToVRM(clip);

                            if (currentAction) {
                                currentAction.stop();
                            }

                            currentAction = mixer.clipAction(retargetedClip);
                            currentAction.loop = THREE.LoopRepeat;
                            currentAction.clampWhenFinished = false;
                            currentAction.play();

                            console.log(`[OK] VRMA loaded: ${vrmaPath}`);
                            document.getElementById('anim-name').textContent = `VRMA: ${vrmaPath.split('/').pop()}`;
                            return true;  // Success!
                        }
                    }
                } catch (error) {
                    console.log(`[INFO] ${vrmaPath} failed:`, error.message);
                }
            }

            // If no VRMA worked, use procedural fallback
            console.log('[WARN] No VRMA files loaded, using procedural animation');
            createEnhancedIdleAnimation();
            return false;
        }

        // Retarget VRMA animation to VRM model
        function retargetAnimationToVRM(clip) {
            if (!currentVRM || !currentVRM.humanoid) return clip;

            const retargetedTracks = [];

            for (const track of clip.tracks) {
                // Extract bone name from track name (e.g., "Hips.quaternion" -> "Hips")
                const trackParts = track.name.split('.');
                const boneName = trackParts[0];
                const propertyName = trackParts[1];

                // Try to find corresponding VRM bone
                let vrmBone = null;

                // Map common bone names to VRM humanoid bones
                const boneMap = {
                    'Hips': 'hips',
                    'Spine': 'spine',
                    'Chest': 'chest',
                    'UpperChest': 'upperChest',
                    'Neck': 'neck',
                    'Head': 'head',
                    'LeftShoulder': 'leftShoulder',
                    'LeftUpperArm': 'leftUpperArm',
                    'LeftLowerArm': 'leftLowerArm',
                    'LeftHand': 'leftHand',
                    'RightShoulder': 'rightShoulder',
                    'RightUpperArm': 'rightUpperArm',
                    'RightLowerArm': 'rightLowerArm',
                    'RightHand': 'rightHand',
                    'LeftUpperLeg': 'leftUpperLeg',
                    'LeftLowerLeg': 'leftLowerLeg',
                    'LeftFoot': 'leftFoot',
                    'RightUpperLeg': 'rightUpperLeg',
                    'RightLowerLeg': 'rightLowerLeg',
                    'RightFoot': 'rightFoot'
                };

                const vrmBoneName = boneMap[boneName];
                if (vrmBoneName) {
                    vrmBone = currentVRM.humanoid.getNormalizedBoneNode(vrmBoneName);
                }

                if (vrmBone) {
                    // Create new track targeting the VRM bone
                    const newTrackName = `${vrmBone.name}.${propertyName}`;
                    let newTrack;

                    if (track instanceof THREE.QuaternionKeyframeTrack) {
                        newTrack = new THREE.QuaternionKeyframeTrack(newTrackName, track.times, track.values);
                    } else if (track instanceof THREE.VectorKeyframeTrack) {
                        newTrack = new THREE.VectorKeyframeTrack(newTrackName, track.times, track.values);
                    } else if (track instanceof THREE.NumberKeyframeTrack) {
                        newTrack = new THREE.NumberKeyframeTrack(newTrackName, track.times, track.values);
                    }

                    if (newTrack) {
                        retargetedTracks.push(newTrack);
                    }
                }
            }

            console.log(`[DEBUG] Retargeted ${retargetedTracks.length} tracks from ${clip.tracks.length} original tracks`);

            return new THREE.AnimationClip(clip.name, clip.duration, retargetedTracks);
        }

        // Enhanced procedural idle animation with natural pose (fallback)
        function createEnhancedIdleAnimation() {
            if (!currentVRM || !currentVRM.humanoid) return;

            const tracks = [];
            const duration = 6.0;
            const times = [];
            const fps = 30;
            const numFrames = duration * fps;

            for (let i = 0; i <= numFrames; i++) {
                times.push(i / fps);
            }

            // Helper function to create quaternion array
            function createQuatTrack(boneName, eulerFunc) {
                const bone = currentVRM.humanoid.getNormalizedBoneNode(boneName);
                if (!bone) return null;

                const quats = [];
                for (let i = 0; i <= numFrames; i++) {
                    const t = i / fps;
                    const euler = eulerFunc(t);
                    const quat = new THREE.Quaternion();
                    quat.setFromEuler(euler);
                    quats.push(quat.x, quat.y, quat.z, quat.w);
                }
                return new THREE.QuaternionKeyframeTrack(`${bone.name}.quaternion`, times, quats);
            }

            // 1. Natural arm pose (hanging down naturally)
            const leftArmTrack = createQuatTrack('leftUpperArm', (t) => {
                const sway = Math.sin(t * Math.PI * 0.5) * 0.05;
                return new THREE.Euler(0.2 + sway, 0, 0.1);  // Slightly forward, relaxed
            });
            if (leftArmTrack) tracks.push(leftArmTrack);

            const rightArmTrack = createQuatTrack('rightUpperArm', (t) => {
                const sway = Math.sin(t * Math.PI * 0.5 + Math.PI) * 0.05;
                return new THREE.Euler(0.2 + sway, 0, -0.1);
            });
            if (rightArmTrack) tracks.push(rightArmTrack);

            // 2. Breathing - chest expansion
            const chestTrack = createQuatTrack('chest', (t) => {
                const breathCycle = Math.sin(t * Math.PI * 0.5) * 0.015;
                return new THREE.Euler(breathCycle, 0, 0);
            });
            if (chestTrack) tracks.push(chestTrack);

            // 3. Subtle head movement
            const headTrack = createQuatTrack('head', (t) => {
                const headSway = Math.sin(t * Math.PI * 0.3) * 0.03;
                const headTilt = Math.cos(t * Math.PI * 0.25) * 0.02;
                return new THREE.Euler(headSway, headTilt, 0);
            });
            if (headTrack) tracks.push(headTrack);

            // 4. Hip sway (subtle weight shifting)
            const hipsTrack = createQuatTrack('hips', (t) => {
                const sway = Math.sin(t * Math.PI * 0.3) * 0.02;
                return new THREE.Euler(0, sway, 0);
            });
            if (hipsTrack) tracks.push(hipsTrack);

            // 5. Finger micro-movements (left hand)
            const fingerBones = ['leftThumbProximal', 'leftIndexProximal', 'leftMiddleProximal'];
            fingerBones.forEach((boneName, idx) => {
                const track = createQuatTrack(boneName, (t) => {
                    const wiggle = Math.sin(t * Math.PI * 0.8 + idx) * 0.03;
                    return new THREE.Euler(0, 0, wiggle);
                });
                if (track) tracks.push(track);
            });

            // 6. Right hand fingers
            const rightFingerBones = ['rightThumbProximal', 'rightIndexProximal', 'rightMiddleProximal'];
            rightFingerBones.forEach((boneName, idx) => {
                const track = createQuatTrack(boneName, (t) => {
                    const wiggle = Math.sin(t * Math.PI * 0.8 + idx + Math.PI) * 0.03;
                    return new THREE.Euler(0, 0, -wiggle);
                });
                if (track) tracks.push(track);
            });

            const clip = new THREE.AnimationClip('enhanced_idle', duration, tracks);
            currentAction = mixer.clipAction(clip);
            currentAction.loop = THREE.LoopRepeat;
            currentAction.play();

            document.getElementById('anim-name').textContent = 'Enhanced Procedural (Fallback)';
            console.log('[OK] Enhanced idle animation created');
        }

        // Expression system
        function setExpression(emotion, intensity = 1.0) {
            if (!currentVRM || !currentVRM.expressionManager) return;

            const expressionName = EMOTION_MAP[emotion] || 'neutral';

            try {
                currentVRM.expressionManager.setValue('happy', 0);
                currentVRM.expressionManager.setValue('sad', 0);
                currentVRM.expressionManager.setValue('angry', 0);
                currentVRM.expressionManager.setValue('surprised', 0);
                currentVRM.expressionManager.setValue('neutral', 0);
                currentVRM.expressionManager.setValue(expressionName, intensity);

                document.getElementById('emotion-text').textContent =
                    emotion.charAt(0).toUpperCase() + emotion.slice(1);
            } catch (error) {
                console.error('[ERROR] Expression:', error);
            }
        }

        // Lip-sync
        function setViseme(viseme, weight = 1.0) {
            if (!currentVRM || !currentVRM.expressionManager) return;

            const visemeMap = { 'A': 'aa', 'E': 'ee', 'I': 'ih', 'O': 'oh', 'U': 'ou' };
            const vrmViseme = visemeMap[viseme] || 'aa';

            try {
                Object.values(visemeMap).forEach(v => {
                    currentVRM.expressionManager.setValue(v, 0);
                });
                currentVRM.expressionManager.setValue(vrmViseme, weight);
            } catch (error) {}
        }

        // WebSocket
        function connectWebSocket() {
            if (ws && (ws.readyState === WebSocket.OPEN || ws.readyState === WebSocket.CONNECTING)) return;

            ws = new WebSocket('ws://localhost:8000/ws');

            ws.onopen = () => {
                console.log('[OK] WebSocket connected');
                updateStatus('connected', 'Ready');
            };

            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);

                if (data.type === 'emotion') {
                    setExpression(data.emotion, data.intensity || 1.0);
                }
                if (data.type === 'audio') {
                    playAudio(data.audio);
                }
            };

            ws.onerror = (error) => {
                console.error('[ERROR] WebSocket:', error);
                updateStatus('disconnected', 'Error');
            };

            ws.onclose = () => {
                updateStatus('disconnected', 'Disconnected');
                ws = null;
                setTimeout(connectWebSocket, 3000);
            };
        }

        function updateStatus(status, text) {
            const statusDot = document.querySelector('.status-dot');
            const statusText = document.getElementById('status-text');

            statusDot.className = 'status-dot';
            if (status === 'connected') statusDot.classList.add('status-connected');
            else if (status === 'thinking') statusDot.classList.add('status-thinking');
            else statusDot.classList.add('status-disconnected');

            statusText.textContent = text;
        }

        // Audio playback
        async function playAudio(audioBase64) {
            if (currentAudio) currentAudio.pause();

            try {
                const audioData = atob(audioBase64);
                const arrayBuffer = new ArrayBuffer(audioData.length);
                const view = new Uint8Array(arrayBuffer);
                for (let i = 0; i < audioData.length; i++) {
                    view[i] = audioData.charCodeAt(i);
                }

                const blob = new Blob([arrayBuffer], { type: 'audio/wav' });
                const audioUrl = URL.createObjectURL(blob);
                currentAudio = new Audio(audioUrl);

                currentAudio.addEventListener('play', () => { animateMouth(); });
                currentAudio.addEventListener('ended', () => {
                    stopMouth();
                    updateStatus('connected', 'Ready');
                });

                await currentAudio.play();
            } catch (error) {
                console.error('[ERROR] Audio:', error);
            }
        }

        let mouthAnimationFrame = null;
        function animateMouth() {
            const visemes = ['A', 'I', 'U', 'E', 'O'];
            let index = 0;
            function animate() {
                setViseme(visemes[index], 0.7);
                index = (index + 1) % visemes.length;
                mouthAnimationFrame = setTimeout(animate, 100);
            }
            animate();
        }

        function stopMouth() {
            if (mouthAnimationFrame) {
                clearTimeout(mouthAnimationFrame);
                mouthAnimationFrame = null;
            }
            setViseme('A', 0);
        }

        // Speech recognition
        function initSpeechRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                document.getElementById('mic-status').textContent = 'Not supported';
                return;
            }

            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'zh-CN';

            recognition.onstart = () => {
                isListening = true;
                document.getElementById('talk-btn').classList.add('recording');
                document.getElementById('mic-status').textContent = 'Listening...';
                updateStatus('thinking', 'Listening...');
            };

            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                sendTextToAI(transcript);
            };

            recognition.onerror = (event) => {
                console.error('[ERROR] Speech:', event.error);
                updateStatus('connected', 'Ready');
                isListening = false;
                document.getElementById('talk-btn').classList.remove('recording');
            };

            recognition.onend = () => {
                isListening = false;
                document.getElementById('talk-btn').classList.remove('recording');
                document.getElementById('mic-status').textContent = 'Click and speak';
            };
        }

        function sendTextToAI(text) {
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                console.error('[ERROR] WebSocket not connected');
                updateStatus('disconnected', 'Not connected');
                return;
            }

            updateStatus('thinking', 'Thinking...');
            ws.send(JSON.stringify({ type: 'user_input', text: text }));
        }

        // Button events
        document.getElementById('talk-btn').addEventListener('mousedown', () => {
            if (recognition && !isListening) {
                try { recognition.start(); } catch (error) { console.error(error); }
            }
        });

        document.getElementById('talk-btn').addEventListener('mouseup', () => {
            if (recognition && isListening) recognition.stop();
        });

        // Animation loop
        function animate() {
            requestAnimationFrame(animate);

            const delta = clock.getDelta();

            if (currentVRM) {
                currentVRM.update(delta);
            }

            if (mixer) {
                mixer.update(delta);
            }

            controls.update();
            renderer.render(scene, camera);
        }

        // Initialize
        window.addEventListener('load', async () => {
            initScene();
            await loadVRM();
            initSpeechRecognition();
            connectWebSocket();
            animate();
        });

        // Debug
        window.ani = {
            setExpression,
            sendText: sendTextToAI,
            vrm: () => currentVRM,
            mixer: () => mixer,
            action: () => currentAction
        };
    </script>
</body>
</html>
