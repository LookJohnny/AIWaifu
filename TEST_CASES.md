# üß™ Test Cases: Day 2 - 3D Character Animation Integration

**Project**: Ani - AI Voice Companion
**Date**: 2025-10-02
**Test Phase**: 3D Animation Integration with VSeeFace

---

## üìã Test Overview

### Test Environment
- **OS**: Windows 11
- **GPU**: RTX 4060 8GB
- **CPU**: (Your CPU model)
- **RAM**: (Your RAM amount)
- **Python**: 3.11+
- **Browser**: Chrome/Edge (latest)

### Software Under Test
- **VRoid Studio**: Latest
- **VSeeFace**: v1.13.38+
- **OBS Studio**: v30.0+
- **Backend**: main_full.py + animation_controller.py
- **TTS**: XTTS-v2
- **LLM**: qwen2.5:7b via Ollama

### Test Data
- **Voice samples**: English and Chinese speech
- **Character**: ani_character.vrm
- **Emotions**: joy, sad, anger, surprise, neutral

---

## üéØ Test Categories

1. **Unit Tests** - Individual component testing
2. **Integration Tests** - Component interaction testing
3. **System Tests** - End-to-end pipeline testing
4. **Performance Tests** - Speed and resource usage
5. **Edge Case Tests** - Unusual scenarios and error handling
6. **User Acceptance Tests** - Real-world usage scenarios

---

## 1Ô∏è‚É£ UNIT TESTS

### UT-01: VRoid Character Export
**Objective**: Verify character exports correctly from VRoid Studio

**Prerequisites**:
- VRoid Studio installed
- Character created and saved

**Test Steps**:
1. Open VRoid Studio
2. Load character project: `ani_project.vroid`
3. Navigate to Camera/Exporter tab
4. Select "VRM Export"
5. Configure settings:
   - VRM version: 0.0
   - Texture size: 2048x2048
   - Reduce blend shapes: OFF
6. Export to: `F:\Ani\character\ani_character.vrm`

**Expected Results**:
- ‚úÖ Export completes without errors
- ‚úÖ File created: `ani_character.vrm`
- ‚úÖ File size: 10-50MB
- ‚úÖ No warning messages about missing data

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UT-02: VSeeFace VRM Loading
**Objective**: Verify VSeeFace can load VRM character

**Prerequisites**:
- VSeeFace installed
- ani_character.vrm exists

**Test Steps**:
1. Launch VSeeFace
2. Click "Open VRM"
3. Select `F:\Ani\character\ani_character.vrm`
4. Wait for loading

**Expected Results**:
- ‚úÖ Character loads within 60 seconds
- ‚úÖ Character displays correctly in viewport
- ‚úÖ No error messages
- ‚úÖ All body parts visible (head, body, limbs)
- ‚úÖ Textures loaded correctly

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UT-03: VSeeFace Manual Expression Test
**Objective**: Verify expressions work via keyboard hotkeys

**Prerequisites**:
- VSeeFace running with character loaded

**Test Steps**:
1. Press keyboard key "1"
2. Press keyboard key "2"
3. Press keyboard key "3"
4. Press keyboard key "4"
5. Press keyboard key "5"
6. Continue through keys 1-9

**Expected Results**:
- ‚úÖ Each key triggers different expression
- ‚úÖ Expression changes are clearly visible
- ‚úÖ Transitions are smooth
- ‚úÖ Character returns to neutral when key released
- ‚úÖ Identify joy, sad, anger, surprise mappings

**Actual Results**:
- Key for Joy: ___
- Key for Sad: ___
- Key for Anger: ___
- Key for Surprise: ___
- Key for Neutral: ___

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UT-04: VSeeFace Microphone Lip-sync
**Objective**: Verify lip-sync works with microphone input

**Prerequisites**:
- VSeeFace running with character loaded
- Microphone enabled in VSeeFace settings

**Test Steps**:
1. Enable "Lip sync from microphone" in settings
2. Speak into microphone: "Hello, this is a test"
3. Speak: "Testing one, two, three"
4. Speak: "‰Ω†Â•ΩÔºåÊµãËØï‰∏Ä‰∏ã" (Chinese)

**Expected Results**:
- ‚úÖ Character's mouth opens when speaking
- ‚úÖ Mouth closes when silent
- ‚úÖ Movement roughly matches speech rhythm
- ‚úÖ Works for both English and Chinese
- ‚úÖ Sensitivity can be adjusted

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UT-05: VMC Protocol Connection
**Objective**: Verify VMC receiver is enabled and listening

**Prerequisites**:
- VSeeFace running with character loaded

**Test Steps**:
1. Open VSeeFace settings
2. Navigate to "OSC/VMC" section
3. Enable "VMC protocol receiver"
4. Set port: 39539
5. Set IP: 127.0.0.1
6. Apply settings

**Expected Results**:
- ‚úÖ VMC receiver shows "enabled" or green status
- ‚úÖ Port 39539 is listening (check with netstat)
- ‚úÖ No firewall blocking warnings
- ‚úÖ Settings save successfully

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UT-06: AnimationController Initialization
**Objective**: Verify AnimationController class initializes correctly

**Prerequisites**:
- python-osc installed
- animation_controller.py created

**Test Steps**:
1. Open Python terminal
2. Run:
   ```python
   from animation_controller import AnimationController
   controller = AnimationController()
   ```

**Expected Results**:
- ‚úÖ No import errors
- ‚úÖ Class instantiates successfully
- ‚úÖ OSC client initialized
- ‚úÖ No connection errors (or graceful warning if VSeeFace not running)

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UT-07: AnimationController Expression Commands
**Objective**: Verify AnimationController can send expression commands

**Prerequisites**:
- VSeeFace running with VMC enabled
- AnimationController initialized

**Test Steps**:
1. In Python terminal:
   ```python
   from animation_controller import AnimationController
   import asyncio

   controller = AnimationController()

   # Test each emotion
   asyncio.run(controller.set_expression("joy", 1.0))
   # Wait 2 seconds, observe VSeeFace

   asyncio.run(controller.set_expression("sad", 1.0))
   # Wait 2 seconds, observe VSeeFace

   asyncio.run(controller.set_expression("anger", 1.0))
   # Wait 2 seconds, observe VSeeFace

   asyncio.run(controller.set_expression("surprise", 1.0))
   # Wait 2 seconds, observe VSeeFace

   asyncio.run(controller.set_expression("neutral", 1.0))
   # Wait 2 seconds, observe VSeeFace
   ```

**Expected Results**:
- ‚úÖ "joy" ‚Üí Character shows happy expression
- ‚úÖ "sad" ‚Üí Character shows sad expression
- ‚úÖ "anger" ‚Üí Character shows angry expression
- ‚úÖ "surprise" ‚Üí Character shows surprised expression
- ‚úÖ "neutral" ‚Üí Character returns to neutral
- ‚úÖ Each command executes without errors

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UT-08: AnimationController Intensity Scaling
**Objective**: Verify expression intensity can be controlled

**Prerequisites**:
- VSeeFace running with VMC enabled
- AnimationController initialized

**Test Steps**:
1. In Python terminal:
   ```python
   # Test different intensities for joy
   asyncio.run(controller.set_expression("joy", 0.2))  # 20%
   # Observe expression

   asyncio.run(controller.set_expression("joy", 0.5))  # 50%
   # Observe expression

   asyncio.run(controller.set_expression("joy", 1.0))  # 100%
   # Observe expression
   ```

**Expected Results**:
- ‚úÖ Lower intensity (0.2) ‚Üí Subtle expression
- ‚úÖ Medium intensity (0.5) ‚Üí Moderate expression
- ‚úÖ High intensity (1.0) ‚Üí Full expression
- ‚úÖ Expression strength visibly scales with intensity

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

## 2Ô∏è‚É£ INTEGRATION TESTS

### IT-01: Backend Starts with Animation Controller
**Objective**: Verify main_full.py initializes AnimationController on startup

**Prerequisites**:
- VSeeFace running (or not, to test graceful degradation)
- main_full.py updated with animation integration

**Test Steps**:
1. Open terminal in F:\Ani\
2. Run: `python main_full.py`
3. Check console output

**Expected Results**:
- ‚úÖ Server starts successfully
- ‚úÖ Console shows "Animation controller initialized" (or warning if VSeeFace not running)
- ‚úÖ Server runs on http://localhost:8000
- ‚úÖ No critical errors
- ‚úÖ If VSeeFace not running: Warning logged but server continues

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### IT-02: LLM Emotion Detection Triggers Expression
**Objective**: Verify LLM emotion output triggers AnimationController

**Prerequisites**:
- VSeeFace running with character
- Backend running
- Browser open to http://localhost:8000

**Test Steps**:
1. Click "Start Listening"
2. Say: "Tell me something that makes you happy"
3. Wait for LLM response
4. Observe console logs and VSeeFace

**Expected Results**:
- ‚úÖ LLM generates response
- ‚úÖ Emotion detected in console: "joy" or similar
- ‚úÖ AnimationController called with emotion
- ‚úÖ VSeeFace character shows happy expression
- ‚úÖ Timing: Expression changes during or just before speech

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### IT-03: TTS Audio Triggers Lip-sync
**Objective**: Verify TTS audio output triggers lip-sync in VSeeFace

**Prerequisites**:
- VSeeFace running with character
- Backend running
- Browser open

**Test Steps**:
1. Click "Start Listening"
2. Say: "Count to five"
3. Wait for TTS response
4. Observe character mouth during audio playback

**Expected Results**:
- ‚úÖ TTS audio plays through system
- ‚úÖ VSeeFace detects audio (via system audio monitoring)
- ‚úÖ Character's mouth moves in sync with audio
- ‚úÖ Lip-sync delay < 100ms
- ‚úÖ Mouth closes when audio ends

**Actual Results**:
- Lip-sync delay estimate: ___ ms

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### IT-04: Expression + Lip-sync Simultaneous
**Objective**: Verify expression and lip-sync work together without conflict

**Prerequisites**:
- Full system running

**Test Steps**:
1. Click "Start Listening"
2. Say: "Tell me a happy story" (triggers joy + speech)
3. Observe character during response

**Expected Results**:
- ‚úÖ Character shows happy expression
- ‚úÖ While showing expression, lip-sync still works
- ‚úÖ No conflicts or glitches
- ‚úÖ Expression held throughout speech
- ‚úÖ Returns to neutral after speech ends

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### IT-05: OBS Captures VSeeFace Output
**Objective**: Verify OBS can capture and display VSeeFace window

**Prerequisites**:
- VSeeFace running with character
- OBS Studio running

**Test Steps**:
1. In OBS, create Window Capture source
2. Select VSeeFace window
3. Observe OBS preview

**Expected Results**:
- ‚úÖ VSeeFace window captured
- ‚úÖ Character visible in OBS preview
- ‚úÖ No black screen or blank capture
- ‚úÖ Animations play smoothly in OBS (60fps)
- ‚úÖ Character fills frame appropriately

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### IT-06: OBS Fullscreen to TV
**Objective**: Verify OBS can fullscreen scene to TV display

**Prerequisites**:
- OBS scene configured
- TV connected via HDMI

**Test Steps**:
1. In OBS, right-click scene
2. Select "Fullscreen Projector (Scene)"
3. Choose TV display (Display 2/3/etc.)
4. Observe TV

**Expected Results**:
- ‚úÖ Scene displays fullscreen on TV
- ‚úÖ Character visible and clear
- ‚úÖ No black bars or distortion
- ‚úÖ Resolution matches TV native (1080p or 4K)
- ‚úÖ Smooth playback (no stuttering)

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### IT-07: OBS Audio Routing to TV
**Objective**: Verify TTS audio plays through TV speakers

**Prerequisites**:
- Full system running
- OBS fullscreen on TV

**Test Steps**:
1. In browser, start conversation
2. Say: "Say something"
3. Listen to TV speakers

**Expected Results**:
- ‚úÖ TTS audio plays through TV speakers
- ‚úÖ Audio is clear and understandable
- ‚úÖ Volume is appropriate (not too loud/quiet)
- ‚úÖ No distortion or crackling
- ‚úÖ Synchronized with character lip-sync on TV

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

## 3Ô∏è‚É£ SYSTEM TESTS (End-to-End)

### ST-01: Full Pipeline - English with Joy
**Objective**: Test complete conversation flow in English with positive emotion

**Prerequisites**:
- All systems running (VSeeFace, Backend, OBS on TV)
- Browser open

**Test Steps**:
1. Click "Start Listening" in browser
2. Say clearly: "Hello Ani, tell me some good news about technology"
3. Observe entire pipeline from input to output on TV

**Expected Results**:
- ‚úÖ Speech recognized correctly
- ‚úÖ Status: "Listening..." (blue) ‚Üí "Thinking..." (purple) ‚Üí "Speaking..." (green)
- ‚úÖ LLM generates relevant response
- ‚úÖ Emotion detected: joy (or positive emotion)
- ‚úÖ Character on TV shows happy expression
- ‚úÖ TTS audio plays with correct voice (wzy.wav)
- ‚úÖ Lip-sync matches audio on TV
- ‚úÖ Character returns to neutral idle state
- ‚úÖ Total time: 5-9 seconds from end of speech to start of audio

**Actual Results**:
- Speech recognized: ________________
- Emotion detected: ________________
- Expression shown: ________________
- Total response time: ___ seconds
- Lip-sync quality: ‚òê Excellent ‚òê Good ‚òê Fair ‚òê Poor

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### ST-02: Full Pipeline - Chinese with Sadness
**Objective**: Test complete conversation flow in Chinese with sad emotion

**Prerequisites**:
- All systems running

**Test Steps**:
1. Click "Start Listening"
2. Say in Chinese: "ÁªôÊàëËÆ≤‰∏Ä‰∏™ÊÇ≤‰º§ÁöÑÊïÖ‰∫ã" (Tell me a sad story)
3. Observe pipeline

**Expected Results**:
- ‚úÖ Chinese speech recognized correctly
- ‚úÖ LLM responds in Chinese
- ‚úÖ Emotion detected: sad
- ‚úÖ Character on TV shows sad expression
- ‚úÖ TTS Chinese pronunciation correct
- ‚úÖ Lip-sync works for Chinese speech
- ‚úÖ Full pipeline works same as English

**Actual Results**:
- Speech recognized: ________________
- Emotion detected: ________________
- Response language: ________________
- Lip-sync quality: ‚òê Excellent ‚òê Good ‚òê Fair ‚òê Poor

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### ST-03: Full Pipeline - Surprise Emotion
**Objective**: Test surprise emotion expression

**Prerequisites**:
- All systems running

**Test Steps**:
1. Click "Start Listening"
2. Say: "Tell me something really surprising about AI"
3. Observe response

**Expected Results**:
- ‚úÖ LLM generates surprising fact
- ‚úÖ Emotion detected: surprise
- ‚úÖ Character shows surprised expression (wide eyes, open mouth)
- ‚úÖ Expression is clearly different from other emotions
- ‚úÖ Lip-sync continues to work

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### ST-04: Full Pipeline - Anger Emotion
**Objective**: Test anger emotion expression

**Prerequisites**:
- All systems running

**Test Steps**:
1. Click "Start Listening"
2. Say: "What makes AI systems frustrated or angry?"
3. Observe response

**Expected Results**:
- ‚úÖ LLM generates relevant response
- ‚úÖ Emotion detected: anger
- ‚úÖ Character shows angry expression (furrowed brows, frown)
- ‚úÖ Expression is clearly different from other emotions
- ‚úÖ Lip-sync continues to work

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### ST-05: Full Pipeline - Neutral/Informational
**Objective**: Test neutral responses without strong emotion

**Prerequisites**:
- All systems running

**Test Steps**:
1. Click "Start Listening"
2. Say: "What is 15 multiplied by 7?"
3. Observe response

**Expected Results**:
- ‚úÖ LLM provides factual answer
- ‚úÖ Emotion detected: neutral (or low intensity)
- ‚úÖ Character remains neutral or subtle expression
- ‚úÖ Lip-sync works normally
- ‚úÖ No inappropriate emotional expression

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### ST-06: Multi-turn Conversation
**Objective**: Test conversation flow across multiple turns with varying emotions

**Prerequisites**:
- All systems running

**Test Steps**:
1. Turn 1: "Hello, how are you?" (neutral/joy)
2. Turn 2: "Tell me something sad" (sad)
3. Turn 3: "Now tell me something happy" (joy)
4. Turn 4: "Give me a surprise" (surprise)
5. Turn 5: "What's frustrating about that?" (anger)

**Expected Results**:
- ‚úÖ All 5 turns complete successfully
- ‚úÖ Each emotion triggers correctly
- ‚úÖ Expressions transition smoothly between turns
- ‚úÖ No lag or performance degradation
- ‚úÖ Chat history updates correctly
- ‚úÖ Character returns to neutral between turns

**Actual Results**:
- Turn 1 emotion: ________________
- Turn 2 emotion: ________________
- Turn 3 emotion: ________________
- Turn 4 emotion: ________________
- Turn 5 emotion: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### ST-07: Long Response (30+ seconds)
**Objective**: Test system with extended TTS audio

**Prerequisites**:
- All systems running

**Test Steps**:
1. Click "Start Listening"
2. Say: "Tell me a detailed story about the future of artificial intelligence, at least 5 sentences long"
3. Observe entire response

**Expected Results**:
- ‚úÖ LLM generates long response (30+ seconds audio)
- ‚úÖ Emotion detected and expression shown
- ‚úÖ Lip-sync continues throughout entire duration
- ‚úÖ Expression held or transitions naturally
- ‚úÖ Audio doesn't cut off prematurely
- ‚úÖ Character doesn't freeze or glitch
- ‚úÖ Returns to neutral when complete

**Actual Results**:
- Response duration: ___ seconds
- Lip-sync consistency: ‚òê Perfect ‚òê Good ‚òê Degraded

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

## 4Ô∏è‚É£ PERFORMANCE TESTS

### PT-01: Response Time Measurement
**Objective**: Measure total response time for conversation

**Prerequisites**:
- All systems running

**Test Steps**:
1. Prepare stopwatch/timer
2. Click "Start Listening"
3. Say: "Hello"
4. Start timer when you stop speaking
5. Stop timer when TTS audio starts
6. Repeat 5 times for average

**Expected Results**:
- ‚úÖ Average response time: 5-9 seconds
- ‚úÖ Consistent across multiple tests
- ‚úÖ No significant outliers

**Actual Results**:
- Test 1: ___ seconds
- Test 2: ___ seconds
- Test 3: ___ seconds
- Test 4: ___ seconds
- Test 5: ___ seconds
- **Average: ___ seconds**

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### PT-02: Expression Change Latency
**Objective**: Measure time from emotion detection to expression change

**Prerequisites**:
- All systems running

**Test Steps**:
1. Monitor console logs (show timestamps)
2. Start conversation
3. Note timestamp when "Emotion detected: joy" logged
4. Note timestamp when expression changes in VSeeFace
5. Calculate difference

**Expected Results**:
- ‚úÖ Expression change delay: < 200ms
- ‚úÖ Perceptually instant

**Actual Results**:
- Expression change delay: ___ ms

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### PT-03: Lip-sync Delay
**Objective**: Measure delay between audio and lip movement

**Prerequisites**:
- All systems running

**Test Steps**:
1. Play simple response: "One, two, three, four, five"
2. Watch character mouth closely
3. Estimate delay between audio start and mouth movement
4. Repeat multiple times

**Expected Results**:
- ‚úÖ Lip-sync delay: < 100ms
- ‚úÖ Perceptually synchronized
- ‚úÖ No noticeable lag

**Actual Results**:
- Estimated delay: ___ ms
- Perception: ‚òê Perfect sync ‚òê Slight delay ‚òê Noticeable lag

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### PT-04: GPU Usage
**Objective**: Monitor GPU utilization during operation

**Prerequisites**:
- All systems running
- Task Manager open (Performance ‚Üí GPU)

**Test Steps**:
1. Baseline: Note GPU usage with just VSeeFace idle: ___%
2. Start conversation
3. During LLM processing: Note GPU usage: ___%
4. During TTS generation: Note GPU usage: ___%
5. During idle between turns: Note GPU usage: ___%

**Expected Results**:
- ‚úÖ Average GPU usage: < 80%
- ‚úÖ No sustained 100% usage
- ‚úÖ GPU has headroom for other tasks

**Actual Results**:
- VSeeFace idle: ___%
- During LLM: ___%
- During TTS: ___%
- During conversation: ___% average
- Peak usage: ___%

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### PT-05: CPU Usage
**Objective**: Monitor CPU utilization during operation

**Prerequisites**:
- All systems running
- Task Manager open (Performance ‚Üí CPU)

**Test Steps**:
1. Baseline: Note CPU usage at idle: ___%
2. During conversation: Note average CPU usage: ___%
3. Peak CPU during LLM processing: ___%

**Expected Results**:
- ‚úÖ Average CPU usage: < 60%
- ‚úÖ Peak CPU: < 90%
- ‚úÖ System remains responsive

**Actual Results**:
- Idle CPU: ___%
- Average during conversation: ___%
- Peak CPU: ___%

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### PT-06: Memory Usage
**Objective**: Monitor RAM usage and detect memory leaks

**Prerequisites**:
- All systems running
- Task Manager open (Performance ‚Üí Memory)

**Test Steps**:
1. Note initial RAM usage: ___ GB
2. Run 10 conversations (various lengths)
3. Note RAM usage after each conversation
4. Check for increasing trend

**Expected Results**:
- ‚úÖ RAM usage stable or minor increase
- ‚úÖ No memory leak (unbounded growth)
- ‚úÖ System doesn't run out of memory

**Actual Results**:
- Initial RAM: ___ GB
- After 5 conversations: ___ GB
- After 10 conversations: ___ GB
- Trend: ‚òê Stable ‚òê Slight increase ‚òê Concerning growth

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### PT-07: VSeeFace Frame Rate
**Objective**: Verify VSeeFace maintains 60 FPS

**Prerequisites**:
- VSeeFace running with character

**Test Steps**:
1. Check VSeeFace settings for FPS display (enable if available)
2. Or estimate visually (smooth = 60fps, choppy = lower)
3. Monitor FPS during:
   - Idle: ___ fps
   - Expression changes: ___ fps
   - Lip-sync: ___ fps

**Expected Results**:
- ‚úÖ Maintains 60 FPS consistently
- ‚úÖ No dropped frames during animations
- ‚úÖ Smooth visual experience

**Actual Results**:
- Idle FPS: ___ fps
- During animation: ___ fps
- Assessment: ‚òê Smooth (60fps) ‚òê Acceptable (30-60fps) ‚òê Choppy (<30fps)

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### PT-08: Stability Test (15 minutes)
**Objective**: Verify system runs stably for extended period

**Prerequisites**:
- All systems running

**Test Steps**:
1. Start timer for 15 minutes
2. Have 6-8 conversations during this period (varied content)
3. Monitor for:
   - Crashes
   - Error messages
   - Performance degradation
   - Memory/resource issues

**Expected Results**:
- ‚úÖ No crashes in any component
- ‚úÖ No error messages or warnings
- ‚úÖ Performance remains consistent
- ‚úÖ All features continue working
- ‚úÖ System responsive throughout

**Actual Results**:
- Conversations completed: ___
- Crashes: ‚òê None ‚òê VSeeFace ‚òê Backend ‚òê OBS ‚òê Browser
- Errors: ‚òê None ‚òê Minor ‚òê Major
- Performance: ‚òê Stable ‚òê Degraded slightly ‚òê Degraded significantly

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

## 5Ô∏è‚É£ EDGE CASE TESTS

### EC-01: VSeeFace Not Running
**Objective**: Verify graceful degradation when VSeeFace unavailable

**Prerequisites**:
- VSeeFace CLOSED (not running)
- Backend ready to start

**Test Steps**:
1. Ensure VSeeFace is not running
2. Start backend: `python main_full.py`
3. Check console output
4. Try conversation in browser

**Expected Results**:
- ‚úÖ Backend starts successfully (doesn't crash)
- ‚úÖ Console shows warning: "Animation controller unavailable" or similar
- ‚úÖ Voice conversation still works (voice-only mode)
- ‚úÖ No critical errors
- ‚úÖ System functional without animation

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### EC-02: VMC Connection Lost Mid-Session
**Objective**: Test recovery when VSeeFace closes during operation

**Prerequisites**:
- Full system running with active conversation

**Test Steps**:
1. Start a conversation
2. During response, close VSeeFace
3. Observe backend behavior
4. Try another conversation

**Expected Results**:
- ‚úÖ Backend logs warning about lost connection
- ‚úÖ Backend doesn't crash
- ‚úÖ Voice conversation continues working
- ‚úÖ Reconnects if VSeeFace restarted

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### EC-03: Rapid Expression Changes
**Objective**: Test system with multiple emotions in quick succession

**Prerequisites**:
- All systems running

**Test Steps**:
1. Craft prompt that triggers multiple emotions: "Tell me a story that starts happy, becomes sad, then surprising, then angry, and ends neutral"
2. Observe expression changes during long response

**Expected Results**:
- ‚úÖ Multiple expressions detected
- ‚úÖ Character transitions smoothly between expressions
- ‚úÖ No expression conflicts or glitches
- ‚úÖ Lip-sync continues throughout
- ‚úÖ No crashes

**Actual Results**:
- Number of expression changes: ___
- Transitions: ‚òê Smooth ‚òê Acceptable ‚òê Glitchy

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### EC-04: Very Short Response (1-2 words)
**Objective**: Test with minimal TTS output

**Prerequisites**:
- All systems running

**Test Steps**:
1. Click "Start Listening"
2. Say: "Say yes"
3. Observe response

**Expected Results**:
- ‚úÖ LLM responds with short answer
- ‚úÖ Expression triggers (even if brief)
- ‚úÖ Lip-sync works for short audio
- ‚úÖ Character returns to neutral quickly
- ‚úÖ No errors

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### EC-05: Interruption During Speech
**Objective**: Test user interrupting AI response

**Prerequisites**:
- All systems running

**Test Steps**:
1. Start conversation with long response: "Tell me a long story"
2. While AI is speaking, click "Start Listening" again (interrupt)
3. Say: "Stop, tell me something else"

**Expected Results**:
- ‚úÖ Audio playback stops (or continues, depends on implementation)
- ‚úÖ New speech recognized
- ‚úÖ New response generated
- ‚úÖ Expression updates accordingly
- ‚úÖ No crashes or stuck states

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### EC-06: No Microphone Input (Silence)
**Objective**: Test system when user says nothing

**Prerequisites**:
- All systems running

**Test Steps**:
1. Click "Start Listening"
2. Don't say anything for 10 seconds
3. Observe behavior

**Expected Results**:
- ‚úÖ System times out gracefully
- ‚úÖ Returns to idle state
- ‚úÖ No error shown to user (or helpful message)
- ‚úÖ Character remains in neutral/idle

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### EC-07: Background Noise Interference
**Objective**: Test with ambient noise

**Prerequisites**:
- All systems running
- Noise source (music, fan, TV in background)

**Test Steps**:
1. Play background noise at moderate volume
2. Click "Start Listening"
3. Say: "Hello, can you hear me?"
4. Observe recognition quality

**Expected Results**:
- ‚úÖ Speech still recognized (may have minor errors)
- ‚úÖ System doesn't recognize noise as speech
- ‚úÖ Conversation flow continues
- ‚úÖ Acceptable degradation in noisy environment

**Actual Results**:
- Recognition accuracy: ‚òê Perfect ‚òê Good ‚òê Degraded ‚òê Failed

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### EC-08: Mixed Language in One Response
**Objective**: Test when LLM mixes English and Chinese

**Prerequisites**:
- All systems running

**Test Steps**:
1. Click "Start Listening"
2. Say: "Tell me about ‰∫∫Â∑•Êô∫ËÉΩ in both English and Chinese" (mix languages)
3. Observe response

**Expected Results**:
- ‚úÖ LLM handles mixed language request
- ‚úÖ TTS handles both languages (may sound unnatural)
- ‚úÖ Lip-sync works for both
- ‚úÖ Expression triggers correctly
- ‚úÖ No crashes

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### EC-09: OBS Window Minimized/Hidden
**Objective**: Test when OBS is not visible

**Prerequisites**:
- All systems running
- OBS minimized to taskbar

**Test Steps**:
1. Minimize OBS window
2. Have conversation
3. Restore OBS window
4. Check if display still working

**Expected Results**:
- ‚úÖ OBS continues capturing in background
- ‚úÖ When restored, display is still working
- ‚úÖ Fullscreen projector still active
- ‚úÖ No visual glitches

**Actual Results**: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### EC-10: System Resource Exhaustion
**Objective**: Test behavior when system is under heavy load

**Prerequisites**:
- All systems running
- Start resource-intensive task (e.g., video encoding, game)

**Test Steps**:
1. Start heavy background task
2. Attempt conversation
3. Monitor performance

**Expected Results**:
- ‚úÖ System still functional (may be slower)
- ‚úÖ No crashes
- ‚úÖ Graceful performance degradation
- ‚úÖ Error messages if resources unavailable

**Actual Results**:
- System responsiveness: ‚òê Normal ‚òê Slower ‚òê Very slow ‚òê Unresponsive

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

## 6Ô∏è‚É£ USER ACCEPTANCE TESTS

### UAT-01: First-time User Experience
**Objective**: Simulate new user trying system for first time

**Prerequisites**:
- All systems set up and running

**Test Steps**:
1. Ask someone unfamiliar with system to try it
2. Give minimal instructions: "Open browser to localhost:8000 and talk to Ani"
3. Observe their interaction

**Expected Results**:
- ‚úÖ User understands how to start conversation
- ‚úÖ User finds it intuitive
- ‚úÖ Character behavior is natural and engaging
- ‚úÖ User has positive experience

**Actual Results**:
- User feedback: ________________
- Ease of use (1-10): ___
- Enjoyment (1-10): ___

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UAT-02: TV Display Quality
**Objective**: Evaluate visual quality on large TV screen

**Prerequisites**:
- OBS fullscreen on TV

**Test Steps**:
1. View character on TV from normal viewing distance (6-10 feet)
2. Have conversation and observe
3. Rate visual quality

**Expected Results**:
- ‚úÖ Character is clearly visible from across room
- ‚úÖ Expressions are noticeable and engaging
- ‚úÖ No pixelation or blurriness
- ‚úÖ Colors are vibrant and appealing
- ‚úÖ Professional appearance

**Actual Results**:
- Visual clarity (1-10): ___
- Expression visibility (1-10): ___
- Overall appearance (1-10): ___

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UAT-03: Audio Quality on TV Speakers
**Objective**: Evaluate audio quality through TV

**Prerequisites**:
- Audio routing to TV speakers

**Test Steps**:
1. Have conversation with AI
2. Listen from normal viewing distance
3. Rate audio quality

**Expected Results**:
- ‚úÖ Voice is clear and understandable
- ‚úÖ Volume is appropriate
- ‚úÖ No distortion or static
- ‚úÖ Chinese and English both clear
- ‚úÖ Professional quality

**Actual Results**:
- Clarity (1-10): ___
- Volume appropriateness (1-10): ___
- Overall audio quality (1-10): ___

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UAT-04: Emotional Expressiveness
**Objective**: Evaluate how well emotions are conveyed

**Prerequisites**:
- All systems running

**Test Steps**:
1. Have conversations triggering all 5 emotions
2. Rate how well each emotion is expressed

**Expected Results**:
- ‚úÖ Joy is clearly recognizable
- ‚úÖ Sadness is clearly recognizable
- ‚úÖ Anger is clearly recognizable
- ‚úÖ Surprise is clearly recognizable
- ‚úÖ Neutral is natural baseline
- ‚úÖ Emotions enhance conversation experience

**Actual Results**:
- Joy expressiveness (1-10): ___
- Sad expressiveness (1-10): ___
- Anger expressiveness (1-10): ___
- Surprise expressiveness (1-10): ___
- Neutral naturalness (1-10): ___
- Overall emotional engagement (1-10): ___

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UAT-05: Lip-sync Realism
**Objective**: Evaluate perceived quality of lip-sync

**Prerequisites**:
- All systems running

**Test Steps**:
1. Have several conversations
2. Watch lip movements closely
3. Rate realism

**Expected Results**:
- ‚úÖ Lip-sync appears natural
- ‚úÖ Matches speech rhythm
- ‚úÖ Not distractingly off
- ‚úÖ Enhances immersion

**Actual Results**:
- Lip-sync realism (1-10): ___
- Immersion level (1-10): ___
- Assessment: ‚òê Excellent ‚òê Good ‚òê Acceptable ‚òê Needs work

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

### UAT-06: Overall User Satisfaction
**Objective**: Gauge overall satisfaction with Day 2 features

**Prerequisites**:
- All systems running
- Multiple test conversations completed

**Test Steps**:
1. Use system for 15-20 minutes
2. Test various features
3. Rate overall experience

**Expected Results**:
- ‚úÖ System is engaging and fun to use
- ‚úÖ 3D character adds value over voice-only
- ‚úÖ User would want to use it again
- ‚úÖ Feels like complete AI companion experience

**Actual Results**:
- Overall satisfaction (1-10): ___
- Would recommend to others: ‚òê Yes ‚òê No
- Favorite feature: ________________
- Improvement suggestion: ________________

**Status**: ‚òê PASS ‚òê FAIL ‚òê SKIP

**Notes**: ________________

---

## üìà Test Summary Report

### Test Execution Summary

| Category | Total Tests | Passed | Failed | Skipped | Pass Rate |
|----------|-------------|--------|--------|---------|-----------|
| Unit Tests (UT) | 8 | ___ | ___ | ___ | __% |
| Integration Tests (IT) | 7 | ___ | ___ | ___ | __% |
| System Tests (ST) | 7 | ___ | ___ | ___ | __% |
| Performance Tests (PT) | 8 | ___ | ___ | ___ | __% |
| Edge Case Tests (EC) | 10 | ___ | ___ | ___ | __% |
| User Acceptance (UAT) | 6 | ___ | ___ | ___ | __% |
| **TOTAL** | **46** | **___** | **___** | **___** | **___%** |

### Critical Issues Found
1. ________________
2. ________________
3. ________________

### Non-Critical Issues Found
1. ________________
2. ________________
3. ________________

### Performance Metrics Summary
- **Average Response Time**: ___ seconds (Target: 5-9s)
- **Expression Change Delay**: ___ ms (Target: <200ms)
- **Lip-sync Delay**: ___ ms (Target: <100ms)
- **Average GPU Usage**: ___% (Target: <80%)
- **Average CPU Usage**: ___% (Target: <60%)
- **VSeeFace FPS**: ___ fps (Target: 60fps)

### Overall Assessment
- ‚òê **PASS** - All critical tests passed, system ready for use
- ‚òê **CONDITIONAL PASS** - Minor issues found, but system functional
- ‚òê **FAIL** - Critical issues prevent system from working properly

### Tester Notes
________________
________________
________________

### Next Steps
- [ ] Fix critical issues (if any)
- [ ] Address non-critical issues
- [ ] Optimize performance (if needed)
- [ ] Update documentation with findings
- [ ] Proceed to polish phase

---

**Test Date**: 2025-10-02
**Tester**: ________________
**System Version**: Day 2 - 3D Animation Integration
**Test Duration**: ___ hours
**Completion Status**: ___% complete

---

## üéØ Acceptance Criteria

To consider Day 2 complete, the following must be TRUE:

### Must Have (Critical)
- [x] At least 90% of Unit Tests pass
- [x] At least 85% of Integration Tests pass
- [x] At least 80% of System Tests pass
- [x] All 5 emotions trigger correctly
- [x] Lip-sync works for both languages
- [x] OBS displays on TV successfully
- [x] No critical crashes or errors
- [x] Performance within acceptable limits

### Should Have (Important)
- [x] At least 70% of Performance Tests pass
- [x] At least 60% of Edge Case Tests pass
- [x] User satisfaction rating > 7/10
- [x] Visual quality rating > 7/10
- [x] Audio quality rating > 7/10

### Nice to Have (Optional)
- [ ] 100% of all tests pass
- [ ] User satisfaction > 9/10
- [ ] Performance exceeds targets
- [ ] No issues found whatsoever

**Status**: ‚òê Acceptance Criteria Met ‚òê Not Met

---

**Good luck with testing! This comprehensive test suite will ensure your Day 2 integration is solid and production-ready!** üß™‚ú®
